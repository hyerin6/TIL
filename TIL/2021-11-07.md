## 테스트

처음엔 서버 한대로 테스트를 진행한다. 

서버 사양: [Compact] 1vCPU, 2GB Mem, 50GB Disk [g1]

<br />

postman으로 게시글 하나를 작성하는데 285ms, 대략 0.3초가 걸린다.    


![create](https://user-images.githubusercontent.com/33855307/140634729-acf0ab4f-9351-4ef3-9378-00431e7c33bf.jpeg)


<br />

천건의 게시글을 작성한다고 가정하면 5분 정도가 걸리고 (300초) 만건은 50분이 된다고 러프하게 가정할 수 있다. 

서버를 늘리지 않고 1K ~ 10K의 데이터를 넣어보자. 

<br />
<br />

### Test1

```yaml
config:
  target: "http://{IP}:8080"
  phases:
    - duration: 333
      arrivalRate: 3
      name: test
  payload:
    path: "ratings_test_1k.csv"
    fields:
      - "content"
scenarios:
  - name: "just post content"
    flow:
      - post:
          headers:
            Authorization: 'Bearer '
          url: "/api/post"
          formData:
            content:  "{{ content }}"
```


1초에 3개의 게시글을 넣을 수 있었다. 

1초에 3개씩, 333초 동안 데이터를 insert 하는 테스트 스크립트를 작성했다. 

999번의 insert가 진행될 예정이다. 

테스트는 약 5분 정도가 걸렸고 다음과 같은 결과를 얻을 수 있었다. 


![test1](https://user-images.githubusercontent.com/33855307/140637480-7d28a23b-6d87-4d1e-9fbe-5e1248f0261c.jpeg)

999번의 요청이 전부 성공했다. 

<br />
<br />

### Test2
```yaml
config:
  target: "http://{IP}:8080"
  phases:
    - duration: 60
      arrivalRate: 3
      name: Warm up
    - duration: 120
      arrivalRate: 3
      rampTo: 100
      name: Ramp up load
    - duration: 600
      arrivalRate: 100
      name: Sustained load
  payload:
    path: "ratings_test_10k.csv"
    fields:
      - "content"
scenarios:
  - name: "just post content"
    flow:
      - post:
          headers: 
            Authorization: 'Bearer '
          url: "/api/post"
          formData:
            content:  "{{ content }}"
```

* Warm up: 60초 동안 초당 3번씩 요청 

* Ramp up load: 120초 동안 초당 3번이었던 요청을 극단적으로 100번까지 늘린다. 

* Sustained load: 600초 동안 초당 100번씩 요청하는 것을 유지 

<br />

실제 서비스에서도 사용자가 갑자기 증가하는 경우가 생긴다. 

이를 잘 처리하는지 여부가 대용량 트래픽을 처리할 수 있는지를 결정하게 된다. 

<br />



![test2](https://user-images.githubusercontent.com/33855307/140644725-832248f4-9e43-42b1-9f77-63b2c1342e71.jpeg)


ramp up이 요청 수가 늘고 타임아웃, 커넥션 리셋이 발생하기도 했다. 

