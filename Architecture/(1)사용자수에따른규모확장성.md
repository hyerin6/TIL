## 단일 서버 

웹 앱, 데이터베이스, 캐시 등이 전부 서버 한 대에서 실행된다.    

<img width="650" src="https://user-images.githubusercontent.com/33855307/143230195-eac1d5ae-4ed6-4216-b1c1-e98a190169cd.jpeg">

<br />

## 데이터베이스   
NoSQL을 고려해야 하는 경우    
* 낮은 응답 지연시간이 요구되는 경우 
* 다루는 데이터가 비정형이라 관계형 데이터가 아닌 경우 
* 데이터를 직렬화하거나 역직렬화하기만 하면 되는 경우 
* 아주 많은 양의 데이터를 저장해야 하는 경우  

<br />

## 스케일업 vs 스케일 아웃    
스케일업은 서버에 고사양 자원(더 좋은 CPU, 더 많은 RAM)을 추가하는 행위이다.       
스케일 아웃은 더 많은 서버를 추가해 성능을 개선하는 행위이다.   

서버로 유입되는 트래픽의 양이 적을 때는 스케일업이 좋은 선택이며   
스케일업은 단순하다는 장점이 있으나 치명적인 단점이 있다.   

* 스케일업은 한계가 있다. 한 대의 서버에 CPU나 메모리를 무한대로 증설할 방법이 없다.   
* 장애에 대한 자동 복구 방안이나 다중화 방안을 제시하지 않는다.    

이러한 단점으로 대규모 애플리케이션을 지원할 때는 스케일 아웃이 필요하다.   
부하 분산기 또는 로드밸런를 도입하는 것이 최선이다.   

<br />  

## 로드 밸런서   
로드밸런서는 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다.    

[Nginx 로드 밸런싱 구성](https://hyerin6.github.io/2021-10-18/loadbalancing/)

* 서버1이 다운되면 모든 트래픽은 서버2로 전송된다. 장애가 발생해도 서비스 전체가 멈추는 것은 아니다. 
* 트래픽이 가파르게 증가하면 더 많은 서버를 추가할 수 있다. 로드밸런스가 자동적으로 트래픽을 분산한다.

<br />

## 데이터베이스 다중화   
보통 서버 사이에 주(master)-부(slave) 관계를 설정하고 데이터 원본은 주 서버에, 사본은 부 서버에 저장하는 방식이다.   

쓰기 연산은 master에서만 지원하고 읽기 연산은 slave에서 지원한다.   

대부분의 애플리케이션은 읽기 연산의 비중이 쓰기 연산보다 훨씬 높기 때문에 slave의 수가 master의 수보다 많다.   

데이터베이스 다중화는 다음과 같은 장점이 있다.    
* 더 나은 성능: 읽기/쓰기 연산이 분산처리 된다. 병렬로 처리될 수 있는 query의 수가 늘어나므로 성능이 좋아진다. 
* 안정성: 데이터베이스 서버에 장애가 생겨도 데이터가 보존된다. 여러 지역으로 다중화시켜 놓을 수 있기 때문이다.  
* 가용성: 데이터를 여러 지역에 복제해 줌으로써, 하나의 데이터베이스 서버에 장애가 발생해도 다른 서버에 있는 데이터로 계속 서비스할 수 있다.   

<br />

## 캐시 
캐시는 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고,   
뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소다.   

#### 캐시 계층   
캐시 계층은 데이터가 잠시 보관되는 곳으로 데이터베이스보다 훨씬 빠르다.  

<br />

#### 캐시 사용 시 유의할 점 
* 캐시는 어떤 상황에 바람직한가? 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하다면 고려해볼 만하다.   



* 어떤 데이터를 캐시에 두어야 하는가? 캐시는 데이터를 휘발성 메모리에 두므로, 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않다.     
  따라서 중요한 데이터는 지속적 저장소(persistent data store)에 두어야 한다.   



* 일관성은 어떻게 유지되는가? 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부다. 
  저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 이 일관성이 깨질 수 있다.   
  참고: <https://timilearning.com/posts/mit-6.824/lecture-16-memcache-at-facebook/>  



* 장애에는 어떻게 대처할 것인가? 캐시 서버를 한 대만 두는 경우 해당 서버는 단일 장애 지점이 된다.   
  이를 피하려면 여러 지역에 걸쳐 캐시 서버를 분산시켜야 한다.   


<br />

## 컨텐츠 전송 네트워크(CDN)  
CDN은 정적 컨텐츠를 전송하는 데 쓰이는 지리, 물리적으로 떨어져 있는 사용자에게 컨텐츠를 더 빠르게 제공할 수 있는 기술이다. 

이미지, 비디오, CSS, JavaScript 파일 등을 캐시할 수 있다.   

간단하게 설명하면 request path, query string, cookie, request header 등의 정보에 기반하여 HTML 페이지를 캐시하는 것이다.   

```
사용자가 원격지에 있는 서버(Origin Server)로 부터 Content  
(ex Web Object, Video, Music, Image, Document 등)를   
다운로드 받을때 가까이 있는 서버에서 받는 것보다 시간이 오래 걸린다.  
그러므로 사용자와 가까운 곳에 위치한 Cache Server에 해당 Content를 저장(캐싱)하고 
Content 요청시에 Cache Server가 응답을 주는 기술이다.
```   


#### CDN 사용 시 고려해야 할 사항 
* 비용      
  CDN은 보통 제3 사업자에 의해 운영되며, 데이터 전송 양에 따라 요금을 내야 한다. 



* 적절한 만료 시한 설정
  


* CDN 장애에 대한 대처 방안 
  CDN 자체가 죽었을 경우 웹사이트/애플리케이션이 어떻게 동작해야 하는지 고려해야 한다.   
  문제를 감지해 원본 서버로부터 직접 컨텐츠를 가져오도록 구성하는 것이 필요하다.   


* 컨텐츠 무효화 방법
  아직 만료되지 않은 컨텐츠라 하더라도 CDN을 제거할 수 있다. 
    - CDN 서비스 사업자가 제공하는 API 사용 
    - 컨텐츠의 다른 버전을 서비스하도록 오브젝트 버저닝 이용  


<br />

## 무상태(stateless) 웹 계층   
이제 웹 계층을 수평적으로 확장하는 방법을 생각해보자.   

이를 위해 상태 정보(사용자 세션 데이터와 같은)를 웹 계층에서 제거해야 한다.   

바람직한 전략으로는 상태 정보를 RDB나 NoSQL과 같은 지속성 저장소에 보관하고    
필요할 때 가져오도록 하는 것이다. 이렇게 구성된 웹 계층을 무상태 웹 계층이라고 부른다.   

<br />

#### 상태 정보 의존적인 아키텍처   
상태 정보를 보관하는 서버는 클라이언트의 정보, 즉 상태를 유지하여 요청들 사이에 공유되도록 한다.   
무상태 서버는 이런 장치가 없다. 

다음은 상태 정보 의존적인 아키텍처이다.   

<img width="650" src="https://user-images.githubusercontent.com/33855307/143240174-da78eb4a-c00e-4e8a-98c0-5d62d577af92.jpeg">


사용자 A의 세션 정보나 프로파일 이미지 같은 상태 정보는 서버 1에 저장된다.   
사용자 A를 인증하기 위해서 HTTP 요청은 반드시 서버1로 전송되어야 한다.   
서버2로 전송되면 인증은 실패한다.   

문제는 같은 클라이언트로부터 요청은 항상 같은 서버로 전송되어야 한다는 것이다.   
대부분의 로드밸런서가 이를 지원하기 위해 고정 세션이라는 기능을 제공하긴 하는데   
이는 로드밸런서에 부담을 준다.   
로드밸런서 뒷단에 서버를 추가하거나 제거하기도 까다로워진다.   
서버의 장애를 처리하기도 복잡해진다.  

<br />

#### 무상태 아키텍처   

<img width="650" src="https://user-images.githubusercontent.com/33855307/143241255-4a526eba-ef5c-4338-b3f1-122efd497283.jpeg">

이 구조에서 사용자로부터 HTTP 요청은 어떤 웹 서버로도 전달될 수 있다.     
웹 서버는 상태 정보가 필요할 경우 공유 저장소로부터 데이터를 가져온다.     
웹 서버로부터 물리적으로 분리되어 있다.   
이런 구조는 단순하고 안정적이며, 규모 확장이 쉽다.   

<br />

## 메시지 큐 
메시지 큐는 메시지의 무손실을 보장하는 비동기 통신을 지원하는 컴포넌트다.   

메시지의 버퍼 역할을 하며 비동기적으로 전송한다.   

* [Message Queue란?](https://hyerin6.github.io/2021-11-08/rabbitmq/)
* [CQRS란?](https://hyerin6.github.io/2021-11-08/cqrs1/)
* [CQRS 구현](https://hyerin6.github.io/2021-11-08/cqrs2/)

메시지 큐를 이용하면 서비스 또는 서버 간 결합이 느슨해져서 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋다.    
생산자는 소비자 프로세스가 다운되어 있어도 메시지를 발생할 수 있고   
소비자는 생산자 서비스가 가용한 상태가 아니더라도 메시지를 수신할 수 있다.   

